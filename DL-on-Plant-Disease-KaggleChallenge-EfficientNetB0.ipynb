{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Essential Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from numpy.random import seed\n",
    "from tensorflow.random import set_seed\n",
    "\n",
    "seed_value=42\n",
    "random.seed(seed_valued)\n",
    "set_seed(seed_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import random\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "from pylab import rcParams\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, Input, GlobalAveragePooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "#from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('E:/Kaggle.Challenges/cassava-leaf-disease-classification/train.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'] = df_train['label'].astype(str)\n",
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 300\n",
    "\n",
    "input_shape = (image_size, image_size, 3)\n",
    "target_size = (image_size, image_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_augmentation = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomCrop(image_size, image_size),\n",
    "                                       tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "                                       tf.keras.layers.experimental.preprocessing.RandomRotation(0, 25),\n",
    "                                       tf.keras.layers.experimental.preprocessing.RandomContrast(0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataGenerator(train_set, val_set):\n",
    "    train_datagen = ImageDataGenerator().flow_from_dataframe(dataframe = train_set,\n",
    "                                                            directory = 'E:/Kaggle.Challenges/cassava-leaf-disease-classification/train_images',\n",
    "                                                            x_col = 'image_id',\n",
    "                                                            y_col = 'label',\n",
    "                                                            target_size = target_size,\n",
    "                                                            batch_size = batch_size,\n",
    "                                                            shuffle = True,\n",
    "                                                            class_mode = 'sparse',\n",
    "                                                            seed = seed_value)\n",
    "    val_datagen = ImageDataGenerator().flow_from_dataframe(dataframe = val_set,\n",
    "                                                          directory = 'E:/Kaggle.Challenges/cassava-leaf-disease-classification/train_images',\n",
    "                                                          x_col = 'image_id',\n",
    "                                                          y_col = 'label',\n",
    "                                                          target_size = target_size,\n",
    "                                                          batch_size = batch_size,\n",
    "                                                          shuffle = False,\n",
    "                                                          class_mode = 'sparse',\n",
    "                                                          seed = seed_value)\n",
    "    \n",
    "return train_datagen, val_datagen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 3\n",
    "total_steps = (int(len(df_train)*0.8/batch_size)+1)*epochs\n",
    "\n",
    "lr = tf.keras.experimental.CosineDecay(initial_learning_rate = 1e-3, decay_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    base_model = EfficientNetB0(include_top = False, weights = 'imagenet', input_shape = input_shape)\n",
    "    \n",
    "    inputs = Input(shape = input_shape)\n",
    "    base = base_model(inputs)\n",
    "    pooling = GlobalAveragePooling2d()(base)\n",
    "    outputs = Dense(5, activation = 'softmax', dtype='float32')(pooling)\n",
    "    \n",
    "    model = Model(inputs = inputs, outputs = outputs)\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr)\n",
    "    model.compile(optimizer = optimizer, loss = 'sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stratified 5-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 0\n",
    "n_splits = 5\n",
    "oof_accuracy = []\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "skf = StratifiedKFold(n_splits = n_splits, random_state = seed_value)\n",
    "\n",
    "for train_index, val_index in skf.split(df_train['image_id'], df['label']):\n",
    "    train_set = df_train.loc[train_index]\n",
    "    val_set = df_train.loc[val_index]\n",
    "    train_datagen, val_datagen = DataGenerator(train_set, val_set)\n",
    "    model = build_model()\n",
    "    print('Training fold no. :' + str(fold_number + 1))\n",
    "    \n",
    "    model_name = 'effnetb0'\n",
    "    fold_name = 'fold.h5'\n",
    "    filepath = model_name + str(fold_number + 1) + fold_name\n",
    "    callbacks = [ModelCheckpoint(filepath = filepath, monitor = 'val_accuracy', save_best_only = True)]\n",
    "    \n",
    "    history = model.fit(train_datagen, epochs = epochs,\n",
    "                       validation_data = val_datagen,\n",
    "                       callbacks = callbacks)\n",
    "    oof_accuracy.append(max(history.history['val_accuracy']))\n",
    "    fold_number += 1\n",
    "    if fold_number == n_splits:\n",
    "        print('Training finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieving out-of-fold accuracy\n",
    "\n",
    "After this, we can see what is out average OOF accuracy.\n",
    "\n",
    "Now to retrieve our OOF predictions, we have to load each model and get them to predict the validation data from their fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "for i in range(5):\n",
    "    effnet = load_model('./effnetb0' + str(i+1) + 'fold.h5')\n",
    "    models.append(effnet)\n",
    "    \n",
    "model_one = models[0]\n",
    "models_two = models[1]\n",
    "models_three = models[2]\n",
    "models_four = models[3]\n",
    "models_five = models[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/Kaggle.Challenges/cassava-leaf-disease-classification/train.csv')\n",
    "val_list = []\n",
    "\n",
    "skf = StratifiedKFold(n_splits = 5, random_state = seed_value)\n",
    "\n",
    "for train_index, val_index in skf.split(df['image_id'], df['label']):\n",
    "    val_list.append(val_index)\n",
    "    \n",
    "one_fold = df.loc[val_list[0]]\n",
    "two_fold = df.loc[val_list[1]]\n",
    "three_fold = df.loc[val_list[2]]\n",
    "four_fold = df.loc[val_list[3]]\n",
    "five_fold = df.fold[val_list[4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tta = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal_and_vertical'),\n",
    "                          tf.keras.layers.experimental.preprocessing.RandomRotation(0.25),\n",
    "                          tf.keras.layers.experimental.preprocessing.RandomContrast(0.2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duplicate_image(img_path, image_size=image_size, tta_runs=2):\n",
    "\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((image_size, image_size))\n",
    "    img_height, img_width = img.size\n",
    "    img = np.array(img)\n",
    "    \n",
    "    img_list = []\n",
    "    for i in range(tta_runs):\n",
    "        img_list.append(img)\n",
    "  \n",
    "    return np.array(img_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_tta(image_filename, folder, tta_runs=2):\n",
    "    \n",
    "    #apply TTA to each of the 3 images and sum all predictions for each local image\n",
    "    localised_predictions = []\n",
    "    local_image_list = duplicate_image(folder+image_filename)\n",
    "    for local_image in local_image_list:\n",
    "        local_image = tf.expand_dims(local_image,0)\n",
    "        augmented_images = [tta(local_image) for i in range(tta_runs)]\n",
    "        predictions = model.predict(np.array(augmented_images[0]))\n",
    "        localised_predictions.append(np.sum(predictions, axis=0))\n",
    "    \n",
    "    #sum all predictions from all 3 images and retrieve the index of the highest value\n",
    "    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n",
    "    max_value = max(global_predictions)\n",
    "    final_prediction = np.argmax(global_predictions)\n",
    "    \n",
    "    return [final_prediction, max_value, global_predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'E:/Kaggle.Challenges/cassava-leaf-disease-classification/train_images/'\n",
    "train_image = \"1000015157.jpg\"\n",
    "predictions = predict_with_tta(train_image, train_folder)\n",
    "\n",
    "print(\"Predicted Label: \", predictions[0])\n",
    "print(\"Predicted Label Value: \", predictions[1])\n",
    "print(\"Predicted One-Hot Label: \", predictions[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confidence Level: {:.2f}\".format(predictions[1]/2*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image_list(image_list, folder):\n",
    "    predictions = []\n",
    "    values = []\n",
    "    with tqdm(total=len(image_list)) as pbar:\n",
    "        for image_filename in image_list:\n",
    "            pbar.update(1)\n",
    "            predictions.append(predict_with_tta(image_filename, folder)[0])\n",
    "            values.append(predict_with_tta(image_filename, folder)[1])\n",
    "    return [predictions, values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 2*0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = (one_fold[\"label\"] != one_fold[\"pred\"]) & (one_fold[\"value\"] >= threshold)\n",
    "one_list = one_fold[mask1].index.to_list()\n",
    "\n",
    "mask2 = (two_fold[\"label\"] != two_fold[\"pred\"]) & (two_fold[\"value\"] >= threshold)\n",
    "two_list = two_fold[mask2].index.to_list()\n",
    "\n",
    "mask3 = (three_fold[\"label\"] != three_fold[\"pred\"]) & (three_fold[\"value\"] >= threshold)\n",
    "three_list = three_fold[mask3].index.to_list()\n",
    "\n",
    "mask4 = (four_fold[\"label\"] != four_fold[\"pred\"]) & (four_fold[\"value\"] >= threshold)\n",
    "four_list = four_fold[mask4].index.to_list()\n",
    "\n",
    "mask5 = (five_fold[\"label\"] != five_fold[\"pred\"]) & (five_fold[\"value\"] >= threshold)\n",
    "five_list = five_fold[mask5].index.to_list()\n",
    "\n",
    "combined_list = list(np.unique(one_list + two_list + three_list + four_list + five_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_train.drop(combined_list, axis='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_number = 0\n",
    "n_splits = 5\n",
    "oof_accuracy = []\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "skf = StratifiedKFold(n_splits=n_splits, random_state=seed_value)\n",
    "for train_index, val_index in skf.split(df[\"image_id\"], df[\"label\"]):\n",
    "    train_set = df.loc[train_index]\n",
    "    val_set = df.loc[val_index]\n",
    "    train_datagen, val_datagen = DataGenerator(train_set, val_set)\n",
    "    model = build_model()\n",
    "    print(\"Training fold no.: \" + str(fold_number+1))\n",
    "\n",
    "    model_name = \"denoised effnetb0 \"\n",
    "    fold_name = \"fold.h5\"\n",
    "    filepath = model_name + str(fold_number+1) + fold_name\n",
    "    callbacks = [ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True)]\n",
    "\n",
    "    history = model.fit(train_datagen, epochs=epochs, validation_data=val_datagen, callbacks=callbacks)\n",
    "    oof_accuracy.append(max(history.history[\"val_accuracy\"]))\n",
    "    fold_number += 1\n",
    "    if fold_number == n_splits:\n",
    "        print(\"Training finished!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
