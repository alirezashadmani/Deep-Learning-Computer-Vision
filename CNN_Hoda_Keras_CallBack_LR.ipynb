{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN_Hoda_Keras_CallBack_LR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezashadmani/Deep-Learning-Course/blob/master/CNN_Hoda_Keras_CallBack_LR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q6RPhepeOmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "afd94369-b689-4b0f-b7d4-dbddfc439dfd"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
        "!mkdir dataset\n",
        "!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-17 09:55:51--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 929 [text/plain]\n",
            "Saving to: ‘dataset.py’\n",
            "\n",
            "\rdataset.py            0%[                    ]       0  --.-KB/s               \rdataset.py          100%[===================>]     929  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-17 09:55:52 (59.1 MB/s) - ‘dataset.py’ saved [929/929]\n",
            "\n",
            "--2020-09-17 09:55:52--  https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat [following]\n",
            "--2020-09-17 09:55:52--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3989009 (3.8M) [application/octet-stream]\n",
            "Saving to: ‘dataset/Data_hoda_full.mat’\n",
            "\n",
            "Data_hoda_full.mat  100%[===================>]   3.80M  20.1MB/s    in 0.2s    \n",
            "\n",
            "2020-09-17 09:55:53 (20.1 MB/s) - ‘dataset/Data_hoda_full.mat’ saved [3989009/3989009]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8z-sW_kfUSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "from dataset import load_hoda\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpHFVToBeOmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123)  # for reproducibility\n",
        "\n",
        "# Load pre-shuffled HODA data into train and test setsdf\n",
        "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n",
        "                                                                        training_sample_size=3500,\n",
        "                                                                        test_sample_size=400,size=28)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n55ay71keOme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scheduler(epoch):\n",
        "  if epoch < 2:\n",
        "    return 0.001\n",
        "  elif epoch < 6:\n",
        "    return 0.0001\n",
        "  else:\n",
        "    return 0.00001\n",
        "learning_rate_scheduler = LearningRateScheduler(scheduler, verbose=1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7l_HdpJeOmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess input data\n",
        "''' 3.1: input data in numpy array format'''\n",
        "x_train = np.array(x_train_original)\n",
        "x_test = np.array(x_test_original)\n",
        "'''3.2 normalize our data values to the range [0, 1]'''\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)\n",
        "\n",
        "\n",
        "# 4. Preprocess class labels\n",
        "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
        "\n",
        "\n",
        "# test and validation set\n",
        "x_val = x_test[:200]\n",
        "x_test = x_test[200:]\n",
        "y_val = y_test[:200]\n",
        "y_test = y_test[200:]\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cgBKzzOeOm5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "da3c0030-0cb0-4804-d163-45ad3b457aa0"
      },
      "source": [
        "# 5. Define model architecture\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "\n",
        "# 6. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "# 7. Fit model on training data\n",
        "history = model.fit(x_train, y_train,\n",
        "          epochs=20, callbacks=[learning_rate_scheduler])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 00001: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 1/20\n",
            "110/110 [==============================] - 0s 4ms/step - loss: 1.2110 - accuracy: 0.5954\n",
            "\n",
            "Epoch 00002: LearningRateScheduler reducing learning rate to 0.001.\n",
            "Epoch 2/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.8454\n",
            "\n",
            "Epoch 00003: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 3/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2839 - accuracy: 0.9074\n",
            "\n",
            "Epoch 00004: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 4/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.9109\n",
            "\n",
            "Epoch 00005: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 5/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2298 - accuracy: 0.9297\n",
            "\n",
            "Epoch 00006: LearningRateScheduler reducing learning rate to 0.0001.\n",
            "Epoch 6/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2269 - accuracy: 0.9237\n",
            "\n",
            "Epoch 00007: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 7/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2138 - accuracy: 0.9320\n",
            "\n",
            "Epoch 00008: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 8/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2029 - accuracy: 0.9366\n",
            "\n",
            "Epoch 00009: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 9/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1962 - accuracy: 0.9340\n",
            "\n",
            "Epoch 00010: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 10/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.2058 - accuracy: 0.9329\n",
            "\n",
            "Epoch 00011: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 11/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1938 - accuracy: 0.9380\n",
            "\n",
            "Epoch 00012: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 12/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1960 - accuracy: 0.9417\n",
            "\n",
            "Epoch 00013: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 13/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1957 - accuracy: 0.9354\n",
            "\n",
            "Epoch 00014: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 14/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1972 - accuracy: 0.9371\n",
            "\n",
            "Epoch 00015: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 15/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1973 - accuracy: 0.9354\n",
            "\n",
            "Epoch 00016: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 16/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1882 - accuracy: 0.9340\n",
            "\n",
            "Epoch 00017: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 17/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1970 - accuracy: 0.9366\n",
            "\n",
            "Epoch 00018: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 18/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1985 - accuracy: 0.9326\n",
            "\n",
            "Epoch 00019: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 19/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1950 - accuracy: 0.9354\n",
            "\n",
            "Epoch 00020: LearningRateScheduler reducing learning rate to 1e-05.\n",
            "Epoch 20/20\n",
            "110/110 [==============================] - 0s 3ms/step - loss: 0.1943 - accuracy: 0.9340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm7Zu4pleOnB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}