{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "CNN_Hoda_Keras_CallBack_LR.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezashadmani/Deep-Learning-Course/blob/master/CNN_Hoda_Keras_CallBack_LR_Finder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q6RPhepeOmE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        },
        "outputId": "e4db7d44-ed61-44f3-b9fe-425df925c52c"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
        "!mkdir dataset\n",
        "!wget https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat -P dataset"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-09-18 11:15:31--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 929 [text/plain]\n",
            "Saving to: ‘dataset.py’\n",
            "\n",
            "\rdataset.py            0%[                    ]       0  --.-KB/s               \rdataset.py          100%[===================>]     929  --.-KB/s    in 0s      \n",
            "\n",
            "2020-09-18 11:15:31 (48.8 MB/s) - ‘dataset.py’ saved [929/929]\n",
            "\n",
            "--2020-09-18 11:15:31--  https://github.com/Alireza-Akhavan/SRU-deeplearning-workshop/raw/master/dataset/Data_hoda_full.mat\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat [following]\n",
            "--2020-09-18 11:15:32--  https://raw.githubusercontent.com/Alireza-Akhavan/SRU-deeplearning-workshop/master/dataset/Data_hoda_full.mat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3989009 (3.8M) [application/octet-stream]\n",
            "Saving to: ‘dataset/Data_hoda_full.mat’\n",
            "\n",
            "Data_hoda_full.mat  100%[===================>]   3.80M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2020-09-18 11:15:32 (36.2 MB/s) - ‘dataset/Data_hoda_full.mat’ saved [3989009/3989009]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkQDs96eoWUI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import the necessary packages\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras import backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tempfile\n",
        "\n",
        "class LearningRateFinder:\n",
        "\tdef __init__(self, model, stopFactor=4, beta=0.98):\n",
        "\t\t# store the model, stop factor, and beta value (for computing\n",
        "\t\t# a smoothed, average loss)\n",
        "\t\tself.model = model\n",
        "\t\tself.stopFactor = stopFactor\n",
        "\t\tself.beta = beta\n",
        "\n",
        "\t\t# initialize our list of learning rates and losses,\n",
        "\t\t# respectively\n",
        "\t\tself.lrs = []\n",
        "\t\tself.losses = []\n",
        "\n",
        "\t\t# initialize our learning rate multiplier, average loss, best\n",
        "\t\t# loss found thus far, current batch number, and weights file\n",
        "\t\tself.lrMult = 1\n",
        "\t\tself.avgLoss = 0\n",
        "\t\tself.bestLoss = 1e9\n",
        "\t\tself.batchNum = 0\n",
        "\t\tself.weightsFile = None\n",
        "\n",
        "\tdef reset(self):\n",
        "\t\t# re-initialize all variables from our constructor\n",
        "\t\tself.lrs = []\n",
        "\t\tself.losses = []\n",
        "\t\tself.lrMult = 1\n",
        "\t\tself.avgLoss = 0\n",
        "\t\tself.bestLoss = 1e9\n",
        "\t\tself.batchNum = 0\n",
        "\t\tself.weightsFile = None\n",
        "\n",
        "\tdef is_data_iter(self, data):\n",
        "\t\t# define the set of class types we will check for\n",
        "\t\titerClasses = [\"NumpyArrayIterator\", \"DirectoryIterator\",\n",
        "\t\t\t \"Iterator\", \"Sequence\"]\n",
        "\n",
        "\t\t# return whether our data is an iterator\n",
        "\t\treturn data.__class__.__name__ in iterClasses\n",
        "\n",
        "\tdef on_batch_end(self, batch, logs):\n",
        "\t\t# grab the current learning rate and add log it to the list of\n",
        "\t\t# learning rates that we've tried\n",
        "\t\tlr = K.get_value(self.model.optimizer.lr)\n",
        "\t\tself.lrs.append(lr)\n",
        "\n",
        "\t\t# grab the loss at the end of this batch, increment the total\n",
        "\t\t# number of batches processed, compute the average average\n",
        "\t\t# loss, smooth it, and update the losses list with the\n",
        "\t\t# smoothed value\n",
        "\t\tl = logs[\"loss\"]\n",
        "\t\tself.batchNum += 1\n",
        "\t\tself.avgLoss = (self.beta * self.avgLoss) + ((1 - self.beta) * l)\n",
        "\t\tsmooth = self.avgLoss / (1 - (self.beta ** self.batchNum))\n",
        "\t\tself.losses.append(smooth)\n",
        "\n",
        "\t\t# compute the maximum loss stopping factor value\n",
        "\t\tstopLoss = self.stopFactor * self.bestLoss\n",
        "\n",
        "\t\t# check to see whether the loss has grown too large\n",
        "\t\tif self.batchNum > 1 and smooth > stopLoss:\n",
        "\t\t\t# stop returning and return from the method\n",
        "\t\t\tself.model.stop_training = True\n",
        "\t\t\treturn\n",
        "\n",
        "\t\t# check to see if the best loss should be updated\n",
        "\t\tif self.batchNum == 1 or smooth < self.bestLoss:\n",
        "\t\t\tself.bestLoss = smooth\n",
        "\n",
        "\t\t# increase the learning rate\n",
        "\t\tlr *= self.lrMult\n",
        "\t\tK.set_value(self.model.optimizer.lr, lr)\n",
        "\n",
        "\tdef find(self, trainData, startLR, endLR, epochs=None,\n",
        "\t\tstepsPerEpoch=None, batchSize=32, sampleSize=2048,\n",
        "\t\tverbose=1):\n",
        "\t\t# reset our class-specific variables\n",
        "\t\tself.reset()\n",
        "\n",
        "\t\t# determine if we are using a data generator or not\n",
        "\t\tuseGen = self.is_data_iter(trainData)\n",
        "\n",
        "\t\t# if we're using a generator and the steps per epoch is not\n",
        "\t\t# supplied, raise an error\n",
        "\t\tif useGen and stepsPerEpoch is None:\n",
        "\t\t\tmsg = \"Using generator without supplying stepsPerEpoch\"\n",
        "\t\t\traise Exception(msg)\n",
        "\n",
        "\t\t# if we're not using a generator then our entire dataset must\n",
        "\t\t# already be in memory\n",
        "\t\telif not useGen:\n",
        "\t\t\t# grab the number of samples in the training data and\n",
        "\t\t\t# then derive the number of steps per epoch\n",
        "\t\t\tnumSamples = len(trainData[0])\n",
        "\t\t\tstepsPerEpoch = np.ceil(numSamples / float(batchSize))\n",
        "\n",
        "\t\t# if no number of training epochs are supplied, compute the\n",
        "\t\t# training epochs based on a default sample size\n",
        "\t\tif epochs is None:\n",
        "\t\t\tepochs = int(np.ceil(sampleSize / float(stepsPerEpoch)))\n",
        "\n",
        "\t\t# compute the total number of batch updates that will take\n",
        "\t\t# place while we are attempting to find a good starting\n",
        "\t\t# learning rate\n",
        "\t\tnumBatchUpdates = epochs * stepsPerEpoch\n",
        "\n",
        "\t\t# derive the learning rate multiplier based on the ending\n",
        "\t\t# learning rate, starting learning rate, and total number of\n",
        "\t\t# batch updates\n",
        "\t\tself.lrMult = (endLR / startLR) ** (1.0 / numBatchUpdates)\n",
        "\n",
        "\t\t# create a temporary file path for the model weights and\n",
        "\t\t# then save the weights (so we can reset the weights when we\n",
        "\t\t# are done)\n",
        "\t\tself.weightsFile = tempfile.mkstemp()[1]\n",
        "\t\tself.model.save_weights(self.weightsFile)\n",
        "\n",
        "\t\t# grab the *original* learning rate (so we can reset it\n",
        "\t\t# later), and then set the *starting* learning rate\n",
        "\t\torigLR = K.get_value(self.model.optimizer.lr)\n",
        "\t\tK.set_value(self.model.optimizer.lr, startLR)\n",
        "\n",
        "\t\t# construct a callback that will be called at the end of each\n",
        "\t\t# batch, enabling us to increase our learning rate as training\n",
        "\t\t# progresses\n",
        "\t\tcallback = LambdaCallback(on_batch_end=lambda batch, logs:\n",
        "\t\t\tself.on_batch_end(batch, logs))\n",
        "\n",
        "\t\t# check to see if we are using a data iterator\n",
        "\t\tif useGen:\n",
        "\t\t\tself.model.fit_generator(\n",
        "\t\t\t\ttrainData,\n",
        "\t\t\t\tsteps_per_epoch=stepsPerEpoch,\n",
        "\t\t\t\tepochs=epochs,\n",
        "\t\t\t\tverbose=verbose,\n",
        "\t\t\t\tcallbacks=[callback])\n",
        "\n",
        "\t\t# otherwise, our entire training data is already in memory\n",
        "\t\telse:\n",
        "\t\t\t# train our model using Keras' fit method\n",
        "\t\t\tself.model.fit(\n",
        "\t\t\t\ttrainData[0], trainData[1],\n",
        "\t\t\t\tbatch_size=batchSize,\n",
        "\t\t\t\tepochs=epochs,\n",
        "\t\t\t\tcallbacks=[callback],\n",
        "\t\t\t\tverbose=verbose)\n",
        "\n",
        "\t\t# restore the original model weights and learning rate\n",
        "\t\tself.model.load_weights(self.weightsFile)\n",
        "\t\tK.set_value(self.model.optimizer.lr, origLR)\n",
        "\n",
        "\tdef plot_loss(self, skipBegin=10, skipEnd=1, title=\"\"):\n",
        "\t\t# grab the learning rate and losses values to plot\n",
        "\t\tlrs = self.lrs[skipBegin:-skipEnd]\n",
        "\t\tlosses = self.losses[skipBegin:-skipEnd]\n",
        "\n",
        "\t\t# plot the learning rate vs. loss\n",
        "\t\tplt.plot(lrs, losses)\n",
        "\t\tplt.xscale(\"log\")\n",
        "\t\tplt.xlabel(\"Learning Rate (Log Scale)\")\n",
        "\t\tplt.ylabel(\"Loss\")\n",
        "\n",
        "\t\t# if the title is not empty, add it to the plot\n",
        "\t\tif title != \"\":\n",
        "\t\t\tplt.title(title)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8z-sW_kfUSp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import datetime\n",
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation\n",
        "import numpy as np\n",
        "from dataset import load_hoda\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpHFVToBeOmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.random.seed(123)  # for reproducibility\n",
        "\n",
        "# Load pre-shuffled HODA data into train and test setsdf\n",
        "x_train_original, y_train_original, x_test_original, y_test_original = load_hoda(\n",
        "                                                                        training_sample_size=3500,\n",
        "                                                                        test_sample_size=400,size=28)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n55ay71keOme",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MIN_LR = 1e-5"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7l_HdpJeOmv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preprocess input data\n",
        "''' 3.1: input data in numpy array format'''\n",
        "x_train = np.array(x_train_original)\n",
        "x_test = np.array(x_test_original)\n",
        "'''3.2 normalize our data values to the range [0, 1]'''\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Reshape to original image shape (n x 784)  ==> (n x 28 x 28 x 1)\n",
        "x_train = x_train.reshape(-1,28,28,1)\n",
        "x_test = x_test.reshape(-1,28,28,1)\n",
        "\n",
        "\n",
        "# 4. Preprocess class labels\n",
        "y_train = keras.utils.to_categorical(y_train_original, num_classes=10)\n",
        "y_test = keras.utils.to_categorical(y_test_original, num_classes=10)\n",
        "\n",
        "\n",
        "# test and validation set\n",
        "x_val = x_test[:200]\n",
        "x_test = x_test[200:]\n",
        "y_val = y_test[:200]\n",
        "y_test = y_test[200:]\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cgBKzzOeOm5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 5. Define model architecture\n",
        "model = Sequential()\n",
        "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
        "                        input_shape=(28, 28, 1)))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((2, 2)))\n",
        "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "opt = tf.keras.optimizers.SGD(lr=MIN_LR, momentum=0.9)\n",
        "\n",
        "# 6. Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=opt,\n",
        "              metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zm7Zu4pleOnB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "7107a9ee-f5f1-4290-e22f-57ecaae7be8b"
      },
      "source": [
        "lrf = LearningRateFinder(model)\n",
        "lrf.find((x_train, y_train), 1e-10, 4e-1)\n",
        "lrf.plot_loss()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/19\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 2.3014 - accuracy: 0.1123\n",
            "Epoch 2/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.3036 - accuracy: 0.1114\n",
            "Epoch 3/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2993 - accuracy: 0.1137\n",
            "Epoch 4/19\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 2.2994 - accuracy: 0.1211\n",
            "Epoch 5/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2999 - accuracy: 0.1194\n",
            "Epoch 6/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2992 - accuracy: 0.1189\n",
            "Epoch 7/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2974 - accuracy: 0.1183\n",
            "Epoch 8/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.3011 - accuracy: 0.1071\n",
            "Epoch 9/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2986 - accuracy: 0.1114\n",
            "Epoch 10/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.3002 - accuracy: 0.1140\n",
            "Epoch 11/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2993 - accuracy: 0.1169\n",
            "Epoch 12/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2926 - accuracy: 0.1223\n",
            "Epoch 13/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2793 - accuracy: 0.1423\n",
            "Epoch 14/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.2214 - accuracy: 0.2409\n",
            "Epoch 15/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 1.6572 - accuracy: 0.4611\n",
            "Epoch 16/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.8350 - accuracy: 0.7011\n",
            "Epoch 17/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.5698 - accuracy: 0.8000\n",
            "Epoch 18/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.7188 - accuracy: 0.7923\n",
            "Epoch 19/19\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 2.3699 - accuracy: 0.1620\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lUX2Qm4U8OX1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}